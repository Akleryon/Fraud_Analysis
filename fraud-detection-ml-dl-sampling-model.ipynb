{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Introduction","metadata":{}},{"cell_type":"markdown","source":"It is fraud detection problems and found there is unbalanced classifiction dataset. To solve that,\n1. we need to test with undersampling, oversampling, mixsampling and non sampling dataset.  \n    There are total 6 datasets. 2 undersampling datasets, 2 oversampling datsets, 1 mix sampling and non sampling dataset.\n2. Train in many models and stacking it. (There are 20 machine learning modles, 1 stacking model, 2 ANN models and 1 CNN model)\n3. Try to build Deep learning model.   \n   \nFor testing puprose, NearMiss undersampling Dataset is mainly used. But If you want to try other dataset and models, just uncomment. ","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\nfrom IPython.display import Image\n\n#Libraries used\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport numpy as np # linear algebra\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nplt.style.use('fivethirtyeight')\nsns.set_style(\"whitegrid\")\n\nfrom plotly import tools \nimport plotly.tools as tls\nimport plotly.offline as py\nimport plotly_express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport missingno as msno\npy.init_notebook_mode(connected=True)\n\nimport cufflinks as cf \nimport collections\nfrom scipy.stats import norm\n\n# Imblearn\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import NearMiss\n\nimport tensorflow as tf \nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Activation\nfrom keras.layers.core import Dense\nfrom keras.optimizers import Adam\nfrom keras.metrics import categorical_crossentropy\n\nfrom sklearn.preprocessing import MinMaxScaler, RobustScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import StratifiedKFold, train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.model_selection import ShuffleSplit\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import PassiveAggressiveClassifier\nfrom sklearn.linear_model import RidgeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neighbors import  RadiusNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.svm import NuSVC\nfrom sklearn.svm import LinearSVC\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom catboost import Pool, CatBoostClassifier, cv\nimport lightgbm as lgb\nimport xgboost as xgb\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score\nfrom sklearn.metrics import auc,roc_auc_score,roc_curve,classification_report,precision_recall_curve\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.decomposition import PCA\n\nimport random\n","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:52:05.995219Z","iopub.execute_input":"2023-04-07T03:52:05.995573Z","iopub.status.idle":"2023-04-07T03:52:06.032313Z","shell.execute_reply.started":"2023-04-07T03:52:05.995542Z","shell.execute_reply":"2023-04-07T03:52:06.031095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Import","metadata":{}},{"cell_type":"code","source":"import os \ndatapath = os.path.join(\"../input/creditcardfraud/\")","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:52:06.034401Z","iopub.execute_input":"2023-04-07T03:52:06.035142Z","iopub.status.idle":"2023-04-07T03:52:06.046962Z","shell.execute_reply.started":"2023-04-07T03:52:06.035104Z","shell.execute_reply":"2023-04-07T03:52:06.045687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd \ncreditcard_df = pd.read_csv(datapath + \"creditcard.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:52:06.049678Z","iopub.execute_input":"2023-04-07T03:52:06.050352Z","iopub.status.idle":"2023-04-07T03:52:07.576314Z","shell.execute_reply.started":"2023-04-07T03:52:06.050311Z","shell.execute_reply":"2023-04-07T03:52:07.575391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Visualization","metadata":{}},{"cell_type":"code","source":"creditcard_df.head(3)","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:52:07.577702Z","iopub.execute_input":"2023-04-07T03:52:07.57794Z","iopub.status.idle":"2023-04-07T03:52:07.87897Z","shell.execute_reply.started":"2023-04-07T03:52:07.577914Z","shell.execute_reply":"2023-04-07T03:52:07.878285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"creditcard_df[\"Class\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:52:07.880981Z","iopub.execute_input":"2023-04-07T03:52:07.88127Z","iopub.status.idle":"2023-04-07T03:52:07.896372Z","shell.execute_reply.started":"2023-04-07T03:52:07.881243Z","shell.execute_reply":"2023-04-07T03:52:07.895141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"creditcard_df.shape, creditcard_df.info()","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:52:07.897782Z","iopub.execute_input":"2023-04-07T03:52:07.898682Z","iopub.status.idle":"2023-04-07T03:52:07.931515Z","shell.execute_reply.started":"2023-04-07T03:52:07.898642Z","shell.execute_reply":"2023-04-07T03:52:07.930289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"creditcard_df[[\"Time\",\"Amount\",\"Class\"]].describe()","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:52:07.932787Z","iopub.execute_input":"2023-04-07T03:52:07.933175Z","iopub.status.idle":"2023-04-07T03:52:07.974604Z","shell.execute_reply.started":"2023-04-07T03:52:07.933135Z","shell.execute_reply":"2023-04-07T03:52:07.973531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking for duplcate entries\ncreditcard_df.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:52:07.975826Z","iopub.execute_input":"2023-04-07T03:52:07.976139Z","iopub.status.idle":"2023-04-07T03:52:08.585545Z","shell.execute_reply.started":"2023-04-07T03:52:07.976108Z","shell.execute_reply":"2023-04-07T03:52:08.584582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# remove duplicate entries\ncreditcard_df.drop_duplicates(keep=False,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:52:08.586657Z","iopub.execute_input":"2023-04-07T03:52:08.586897Z","iopub.status.idle":"2023-04-07T03:52:09.218915Z","shell.execute_reply.started":"2023-04-07T03:52:08.586873Z","shell.execute_reply":"2023-04-07T03:52:09.217863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"timedelta = pd.to_timedelta(creditcard_df['Time'], unit='s')\ncreditcard_df['Time_min'] = (timedelta.dt.components.minutes).astype(int)\ncreditcard_df['Time_hour'] = (timedelta.dt.components.hours).astype(int)","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:52:09.220478Z","iopub.execute_input":"2023-04-07T03:52:09.221123Z","iopub.status.idle":"2023-04-07T03:52:13.692039Z","shell.execute_reply.started":"2023-04-07T03:52:09.221061Z","shell.execute_reply":"2023-04-07T03:52:13.69106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"creditcard_df.tail()","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:52:13.693362Z","iopub.execute_input":"2023-04-07T03:52:13.693601Z","iopub.status.idle":"2023-04-07T03:52:13.71603Z","shell.execute_reply.started":"2023-04-07T03:52:13.693576Z","shell.execute_reply":"2023-04-07T03:52:13.714842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = make_subplots(rows=1,cols=2,subplot_titles=['Distribution of Time', 'Distribution of Amount'])\nfig.add_trace(go.Histogram(name='Time',histnorm='probability',x=creditcard_df.Time),1,1)\nfig.add_trace(go.Histogram(name='Amount',x=creditcard_df.Amount),1,2)\nfig.update_xaxes(mirror=True,linecolor='black',linewidth=2,row=1,col=1)\nfig.update_xaxes(mirror=True,linecolor='black',linewidth=2,row=1,col=2)\nfig.update_yaxes(mirror=True,linecolor='black',linewidth=2,row=1,col=1)\nfig.update_yaxes(mirror=True,linecolor='black',linewidth=2,row=1,col=2)\nfig.update_layout(template='seaborn',width=700,height=300,margin=dict(t=50,b=0,l=0,r=0))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:52:13.717427Z","iopub.execute_input":"2023-04-07T03:52:13.718069Z","iopub.status.idle":"2023-04-07T03:52:15.380635Z","shell.execute_reply.started":"2023-04-07T03:52:13.718032Z","shell.execute_reply":"2023-04-07T03:52:15.379883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_0 = creditcard_df.loc[creditcard_df['Class'] == 0][\"Time\"]\nclass_1 = creditcard_df.loc[creditcard_df['Class'] == 1][\"Time\"]\n\nhist_data = [class_0, class_1]\ngroup_labels = ['Not Fraud', 'Fraud']\n\nfig = ff.create_distplot(hist_data, group_labels, show_hist=False, show_rug=False)\nfig['layout'].update(title='Credit Card Transactions Time Density Plot', xaxis=dict(title='Time [s]'))\niplot(fig, filename='dist_only')","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:52:15.38168Z","iopub.execute_input":"2023-04-07T03:52:15.38204Z","iopub.status.idle":"2023-04-07T03:52:17.075987Z","shell.execute_reply.started":"2023-04-07T03:52:15.382015Z","shell.execute_reply":"2023-04-07T03:52:17.074868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(12,4))\n\nbins = 50\n\nax1.hist(creditcard_df.Time[creditcard_df.Class == 1], bins = bins)\nax1.set_title('Fraud')\n\nax2.hist(creditcard_df.Time[creditcard_df.Class == 0], bins = bins)\nax2.set_title('Non_Fraud')\n\nplt.xlabel('Time (in Seconds)')\nplt.ylabel('Number of Transactions')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:52:17.080557Z","iopub.execute_input":"2023-04-07T03:52:17.080893Z","iopub.status.idle":"2023-04-07T03:52:17.5317Z","shell.execute_reply.started":"2023-04-07T03:52:17.080862Z","shell.execute_reply":"2023-04-07T03:52:17.530581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Exploring the distribuition by Class types throught hours and minutes\nplt.figure(figsize=(12,5))\nsns.distplot(creditcard_df[creditcard_df['Class'] == 0][\"Time_hour\"], \n             color='b')\nsns.distplot(creditcard_df[creditcard_df['Class'] == 1][\"Time_hour\"], \n             color='r')\nplt.title('Fraud x Normal Transactions by Hours', fontsize=17)\nplt.xlim([-1,25])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:52:17.533024Z","iopub.execute_input":"2023-04-07T03:52:17.533325Z","iopub.status.idle":"2023-04-07T03:52:18.632831Z","shell.execute_reply.started":"2023-04-07T03:52:17.533297Z","shell.execute_reply":"2023-04-07T03:52:18.631917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Exploring the distribuition by Class types throught hours and minutes\nplt.figure(figsize=(12,5))\nsns.distplot(creditcard_df[creditcard_df['Class'] == 0][\"Time_min\"], \n             color='b')\nsns.distplot(creditcard_df[creditcard_df['Class'] == 1][\"Time_min\"], \n             color='r')\nplt.title('Fraud x Normal Transactions by minutes', fontsize=17)\nplt.xlim([-1,61])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:52:18.63426Z","iopub.execute_input":"2023-04-07T03:52:18.635362Z","iopub.status.idle":"2023-04-07T03:52:19.654747Z","shell.execute_reply.started":"2023-04-07T03:52:18.635302Z","shell.execute_reply":"2023-04-07T03:52:19.653425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(12,6))\n\nax1.scatter(creditcard_df.Time[creditcard_df.Class == 1], creditcard_df.Amount[creditcard_df.Class == 1])\nax1.set_title('Fraud')\n\nax2.scatter(creditcard_df.Time[creditcard_df.Class == 0], creditcard_df.Amount[creditcard_df.Class == 0])\nax2.set_title('Normal')\n\nplt.xlabel('Time (in Seconds)')\nplt.ylabel('Amount')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:52:19.65635Z","iopub.execute_input":"2023-04-07T03:52:19.657543Z","iopub.status.idle":"2023-04-07T03:52:20.351796Z","shell.execute_reply.started":"2023-04-07T03:52:19.657491Z","shell.execute_reply":"2023-04-07T03:52:20.350761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Looking the Amount and time distribuition of FRAUD transactions\nax = sns.lmplot(y=\"Amount\", x=\"Time_min\", fit_reg=False,aspect=1.8,\n                data=creditcard_df, hue='Class')\nplt.title(\"Amounts by Minutes of Frauds and Normal Transactions\",fontsize=16)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:52:20.353119Z","iopub.execute_input":"2023-04-07T03:52:20.353455Z","iopub.status.idle":"2023-04-07T03:52:22.326875Z","shell.execute_reply.started":"2023-04-07T03:52:20.353421Z","shell.execute_reply":"2023-04-07T03:52:22.325976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = sns.lmplot(y=\"Amount\", x=\"Time_hour\", fit_reg=False,aspect=1.8,\n                data=creditcard_df, hue='Class')\nplt.title(\"Amounts by Hour of Frauds and Normal Transactions\", fontsize=16)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:52:22.328165Z","iopub.execute_input":"2023-04-07T03:52:22.328407Z","iopub.status.idle":"2023-04-07T03:52:24.25469Z","shell.execute_reply.started":"2023-04-07T03:52:22.328382Z","shell.execute_reply":"2023-04-07T03:52:24.253408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.gridspec as gridspec\n#Looking the V's features\ncolumns = creditcard_df.iloc[:,1:29].columns\n\nfrauds = creditcard_df.Class == 1\nnormals = creditcard_df.Class == 0\n\ngrid = gridspec.GridSpec(14, 2)\nplt.figure(figsize=(15,20*4))\n\nfor n, col in enumerate(creditcard_df[columns]):\n    ax = plt.subplot(grid[n])\n    sns.distplot(creditcard_df[col][frauds], bins = 50, color='g') #Will receive the \"semi-salmon\" violin\n    sns.distplot(creditcard_df[col][normals], bins = 50, color='r') #Will receive the \"ocean\" color\n    ax.set_ylabel('Density')\n    ax.set_title(str(col))\n    ax.set_xlabel('')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:52:24.256279Z","iopub.execute_input":"2023-04-07T03:52:24.25665Z","iopub.status.idle":"2023-04-07T03:53:09.088848Z","shell.execute_reply.started":"2023-04-07T03:52:24.256611Z","shell.execute_reply":"2023-04-07T03:53:09.088059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\n\nplt.figure(figsize=(10,10))\ndataplot=sns.heatmap(creditcard_df.corr())\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:53:09.089972Z","iopub.execute_input":"2023-04-07T03:53:09.090442Z","iopub.status.idle":"2023-04-07T03:53:10.273196Z","shell.execute_reply.started":"2023-04-07T03:53:09.090414Z","shell.execute_reply":"2023-04-07T03:53:10.272118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data is highly imbalanced .We will correct it by oversamplying .After correcting we will check the skewness of the data \n\n* Data prepartion (No sampling, Undersampling, Oversampling, mix)  \n* The undersampling take total numnder of minority class. In this case 460.  \n* The oversampling take total number of majority class. In this case 282,493 ","metadata":{}},{"cell_type":"markdown","source":"#### Non sampling dataset","metadata":{}},{"cell_type":"code","source":"X = creditcard_df.drop(['Class'], axis=1)\ny = creditcard_df['Class']\ny.value_counts().to_frame()","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:53:10.274694Z","iopub.execute_input":"2023-04-07T03:53:10.275417Z","iopub.status.idle":"2023-04-07T03:53:10.301543Z","shell.execute_reply.started":"2023-04-07T03:53:10.275375Z","shell.execute_reply":"2023-04-07T03:53:10.300225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X.drop(['Time'], axis=1, inplace=True)\nX.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:53:10.302873Z","iopub.execute_input":"2023-04-07T03:53:10.303223Z","iopub.status.idle":"2023-04-07T03:53:10.331964Z","shell.execute_reply.started":"2023-04-07T03:53:10.303195Z","shell.execute_reply":"2023-04-07T03:53:10.330936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:53:10.333212Z","iopub.execute_input":"2023-04-07T03:53:10.334031Z","iopub.status.idle":"2023-04-07T03:53:10.953162Z","shell.execute_reply.started":"2023-04-07T03:53:10.334002Z","shell.execute_reply":"2023-04-07T03:53:10.952135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:53:10.955442Z","iopub.execute_input":"2023-04-07T03:53:10.955823Z","iopub.status.idle":"2023-04-07T03:53:10.962856Z","shell.execute_reply.started":"2023-04-07T03:53:10.955786Z","shell.execute_reply":"2023-04-07T03:53:10.961887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Note that you can fit_transform the whole oversampled features(train+test) from begining\nsc=StandardScaler()\nscaled_X=sc.fit_transform(X)\nscaled_X","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:53:10.964351Z","iopub.execute_input":"2023-04-07T03:53:10.964644Z","iopub.status.idle":"2023-04-07T03:53:11.069774Z","shell.execute_reply.started":"2023-04-07T03:53:10.964615Z","shell.execute_reply":"2023-04-07T03:53:11.068897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaled_X.shape, y.shape","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:53:11.071302Z","iopub.execute_input":"2023-04-07T03:53:11.071684Z","iopub.status.idle":"2023-04-07T03:53:11.078623Z","shell.execute_reply.started":"2023-04-07T03:53:11.071644Z","shell.execute_reply":"2023-04-07T03:53:11.077418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaled_X = pd.DataFrame(scaled_X, columns=X.columns)\nscaled_X.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:53:11.079918Z","iopub.execute_input":"2023-04-07T03:53:11.080217Z","iopub.status.idle":"2023-04-07T03:53:11.106128Z","shell.execute_reply.started":"2023-04-07T03:53:11.080191Z","shell.execute_reply":"2023-04-07T03:53:11.105325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Undersampling","metadata":{}},{"cell_type":"markdown","source":"NearMiss","metadata":{}},{"cell_type":"code","source":"from imblearn.under_sampling import NearMiss\n# Create an instance of NearMiss\nnm = NearMiss()\n\n# Fit and apply NearMiss to downsample the majority class\nnm_features, nm_labels = nm.fit_resample(scaled_X, y)\n\nnm_features.shape, nm_labels.shape, nm_labels.value_counts()\n","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:53:11.107325Z","iopub.execute_input":"2023-04-07T03:53:11.107582Z","iopub.status.idle":"2023-04-07T03:53:13.596986Z","shell.execute_reply.started":"2023-04-07T03:53:11.107557Z","shell.execute_reply":"2023-04-07T03:53:13.596327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"RandomUnderSampler","metadata":{}},{"cell_type":"code","source":"rus = RandomUnderSampler(random_state=42)\nrs_features, rs_labels = rus.fit_resample(scaled_X,y)\nrs_features.shape, rs_labels.shape, rs_labels.value_counts()\n","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:53:13.59799Z","iopub.execute_input":"2023-04-07T03:53:13.598405Z","iopub.status.idle":"2023-04-07T03:53:13.663999Z","shell.execute_reply.started":"2023-04-07T03:53:13.598377Z","shell.execute_reply":"2023-04-07T03:53:13.66297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Oversampling","metadata":{}},{"cell_type":"code","source":"from imblearn.pipeline import make_pipeline as make_pipeline_imb # To do our transformation in a unique time\nfrom imblearn.over_sampling import SMOTE, ADASYN\nfrom imblearn.metrics import classification_report_imbalanced","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:53:13.665431Z","iopub.execute_input":"2023-04-07T03:53:13.665743Z","iopub.status.idle":"2023-04-07T03:53:13.670428Z","shell.execute_reply.started":"2023-04-07T03:53:13.66571Z","shell.execute_reply":"2023-04-07T03:53:13.669532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"SMOTE","metadata":{}},{"cell_type":"code","source":"smote=SMOTE()\nsm_features,sm_labels=smote.fit_resample(scaled_X,y)\nsm_features.shape,sm_labels.shape, sm_labels.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:53:13.671826Z","iopub.execute_input":"2023-04-07T03:53:13.672381Z","iopub.status.idle":"2023-04-07T03:53:13.965823Z","shell.execute_reply.started":"2023-04-07T03:53:13.672348Z","shell.execute_reply":"2023-04-07T03:53:13.965114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Adasyn","metadata":{}},{"cell_type":"code","source":"# from imblearn.over_sampling import ADASYN\nadasyn = ADASYN()\nad_features, ad_labels = adasyn.fit_resample(scaled_X, y)\nad_features.shape, ad_labels.shape, ad_labels.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:53:13.967147Z","iopub.execute_input":"2023-04-07T03:53:13.967804Z","iopub.status.idle":"2023-04-07T03:53:15.888902Z","shell.execute_reply.started":"2023-04-07T03:53:13.967766Z","shell.execute_reply":"2023-04-07T03:53:15.887959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Mix Sampling","metadata":{}},{"cell_type":"code","source":"from sklearn.utils import resample\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import NearMiss\nimport random\n\n# Perform random under-sampling on the majority class\nrus = NearMiss()\nX_under, y_under = rus.fit_resample(scaled_X, y)\nprint(X_under.shape, y_under.shape)\n\n# Perform random over-sampling on the minority class\nros = SMOTE()\nX_over, y_over = ros.fit_resample(scaled_X, y)\nprint(X_over.shape, y_over.shape)\n\n# Combine the under-sampled majority class and over-sampled minority class\nmix_features = np.vstack([X_under, X_over])\nmix_labels = np.hstack([y_under, y_over])\n\nmix_features.shape, mix_labels.shape\n","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:53:15.890115Z","iopub.execute_input":"2023-04-07T03:53:15.890466Z","iopub.status.idle":"2023-04-07T03:53:18.654982Z","shell.execute_reply.started":"2023-04-07T03:53:15.89043Z","shell.execute_reply":"2023-04-07T03:53:18.653874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mix_features = pd.DataFrame(mix_features, columns=X.columns)","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:53:18.656779Z","iopub.execute_input":"2023-04-07T03:53:18.657189Z","iopub.status.idle":"2023-04-07T03:53:18.661787Z","shell.execute_reply.started":"2023-04-07T03:53:18.657138Z","shell.execute_reply":"2023-04-07T03:53:18.660834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mix_labels = pd.DataFrame(mix_labels)\nmix_labels.columns = ['Class']\nmix_labels.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:53:18.662972Z","iopub.execute_input":"2023-04-07T03:53:18.663792Z","iopub.status.idle":"2023-04-07T03:53:18.679571Z","shell.execute_reply.started":"2023-04-07T03:53:18.663717Z","shell.execute_reply":"2023-04-07T03:53:18.678638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mix_labels.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:53:18.681824Z","iopub.execute_input":"2023-04-07T03:53:18.682314Z","iopub.status.idle":"2023-04-07T03:53:18.705703Z","shell.execute_reply.started":"2023-04-07T03:53:18.68228Z","shell.execute_reply":"2023-04-07T03:53:18.704499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Search for duplicated because model can overfit easily","metadata":{}},{"cell_type":"code","source":"print(f\" NearMiss Duplication : {nm_features.duplicated().sum()} \\n \\\n      Rus Duplication : {rs_features.duplicated().sum()} \\n \\\n      SMOTE Duplication : {sm_features.duplicated().sum()} \\n \\\n      ADASYN Duplication : {ad_features.duplicated().sum()} \\n \\\n      Non Duplication : {scaled_X.duplicated().sum()} \\n \\\n      Mix Duplication : {mix_features.duplicated().sum()}\")","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:53:18.706826Z","iopub.execute_input":"2023-04-07T03:53:18.707146Z","iopub.status.idle":"2023-04-07T03:53:24.615467Z","shell.execute_reply.started":"2023-04-07T03:53:18.707112Z","shell.execute_reply":"2023-04-07T03:53:24.61406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Mix_df =pd.concat([mix_features, mix_labels],ignore_index=False,axis=1,sort=False)\nMix_df","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:53:24.616719Z","iopub.execute_input":"2023-04-07T03:53:24.617006Z","iopub.status.idle":"2023-04-07T03:53:24.721228Z","shell.execute_reply.started":"2023-04-07T03:53:24.616977Z","shell.execute_reply":"2023-04-07T03:53:24.72012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Mix_df.shape","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:53:24.722356Z","iopub.execute_input":"2023-04-07T03:53:24.722746Z","iopub.status.idle":"2023-04-07T03:53:24.729442Z","shell.execute_reply.started":"2023-04-07T03:53:24.722713Z","shell.execute_reply":"2023-04-07T03:53:24.728369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# remove duplicate entries\nMix_df.drop_duplicates(keep=False,inplace=True)\nMix_df.shape , Mix_df.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:53:24.739766Z","iopub.execute_input":"2023-04-07T03:53:24.740068Z","iopub.status.idle":"2023-04-07T03:53:28.287349Z","shell.execute_reply.started":"2023-04-07T03:53:24.74004Z","shell.execute_reply":"2023-04-07T03:53:28.286427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mix_features = Mix_df.drop([\"Class\"],axis=1)\nmix_labels = Mix_df['Class']\nmix_features.shape, mix_labels.shape, mix_labels.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:53:28.288497Z","iopub.execute_input":"2023-04-07T03:53:28.288821Z","iopub.status.idle":"2023-04-07T03:53:28.322906Z","shell.execute_reply.started":"2023-04-07T03:53:28.288787Z","shell.execute_reply":"2023-04-07T03:53:28.321917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Check skewness","metadata":{}},{"cell_type":"code","source":"def check_skewness(x):\n    # this can check relation between each column\n    skew_limit=0.75\n    skew_value=creditcard_df[x.columns].skew()\n    #print(skew_value)\n    skew_col=skew_value[abs(skew_value)>skew_limit]\n    cols=skew_col.index\n    return cols","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:53:28.324914Z","iopub.execute_input":"2023-04-07T03:53:28.325204Z","iopub.status.idle":"2023-04-07T03:53:28.331037Z","shell.execute_reply.started":"2023-04-07T03:53:28.325178Z","shell.execute_reply":"2023-04-07T03:53:28.330046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"skewed_col_sm = check_skewness(sm_features)\nskewed_col_ad = check_skewness(ad_features)\nskewed_col_nm = check_skewness(nm_features)\nskewed_col_rs = check_skewness(rs_features)\nskewed_col_mix = check_skewness(mix_features)\nskewed_col_non = check_skewness(scaled_X)\nprint(f\"SMOTE col : \\n {skewed_col_sm} \\n  \\\n      Adasyn col : \\n {skewed_col_ad} \\n  \\\n      NearMiss col : \\n {skewed_col_nm} \\n  \\\n      Random col : \\n {skewed_col_rs} \\n  \\\n      Mix col : \\n {skewed_col_mix} \\n \\\n      NOn col : \\n {skewed_col_non}\") ","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:53:28.33226Z","iopub.execute_input":"2023-04-07T03:53:28.332646Z","iopub.status.idle":"2023-04-07T03:53:28.824019Z","shell.execute_reply.started":"2023-04-07T03:53:28.332613Z","shell.execute_reply":"2023-04-07T03:53:28.822866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import PowerTransformer\npt=PowerTransformer(standardize=False)\nsm_features[skewed_col_sm]=pt.fit_transform(sm_features[skewed_col_sm])\nad_features[skewed_col_ad]=pt.fit_transform(ad_features[skewed_col_ad])\nnm_features[skewed_col_nm]=pt.fit_transform(nm_features[skewed_col_nm])\nrs_features[skewed_col_rs]=pt.fit_transform(rs_features[skewed_col_rs])\nmix_features[skewed_col_mix]=pt.fit_transform(mix_features[skewed_col_mix])\nscaled_X[skewed_col_non]=pt.fit_transform(scaled_X[skewed_col_non])","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:53:28.825905Z","iopub.execute_input":"2023-04-07T03:53:28.826874Z","iopub.status.idle":"2023-04-07T03:53:58.191459Z","shell.execute_reply.started":"2023-04-07T03:53:28.826825Z","shell.execute_reply":"2023-04-07T03:53:58.1902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train_test_split","metadata":{}},{"cell_type":"code","source":"# This is just showing how to train_test_split and add the whole muliple dataset to one dictory\n\nfrom sklearn.model_selection import train_test_split\nMeta_Dataset = {}\n\nprint(\"Splitting Normal : \")\ntrain_n_features, \\\ntest_n_features, \\\ntrain_n_labels, \\\ntest_n_labels=train_test_split(scaled_X,y,test_size=0.2,random_state=1)\nprint(train_n_features.shape, train_n_labels.shape, test_n_features.shape, test_n_labels.shape)\nMeta_Dataset[\"None\"] = [train_n_features.to_numpy(), train_n_labels.to_numpy(), test_n_features.to_numpy(), test_n_labels.to_numpy()]\n\nprint(\"Splitting SMOTE : \")\ntrain_sm_features, \\\ntest_sm_features, \\\ntrain_sm_labels, \\\ntest_sm_labels=train_test_split(sm_features,sm_labels,test_size=0.2,random_state=1)\nprint(train_sm_features.shape, train_sm_labels.shape, test_sm_features.shape, test_sm_labels.shape)\nMeta_Dataset[\"SMOTE\"] = [train_sm_features.to_numpy(), train_sm_labels.to_numpy(), test_sm_features.to_numpy(), test_sm_labels.to_numpy()]\n\nprint(\"Splitting ADASYN : \")\ntrain_ad_features, \\\ntest_ad_features, \\\ntrain_ad_labels, \\\ntest_ad_labels=train_test_split(ad_features,ad_labels,test_size=0.2,random_state=1)\nprint(train_ad_features.shape, train_ad_labels.shape, test_ad_features.shape, test_ad_labels.shape)\nMeta_Dataset[\"ADASYN\"] = [train_ad_features.to_numpy(), train_ad_labels.to_numpy(), test_ad_features.to_numpy(), test_ad_labels.to_numpy()]\n\nprint(\"Splitting NEARMISS : \")\ntrain_nm_features, \\\ntest_nm_features, \\\ntrain_nm_labels, \\\ntest_nm_labels=train_test_split(nm_features,nm_labels,test_size=0.2,random_state=1)\nprint(train_nm_features.shape, train_nm_labels.shape, test_nm_features.shape, test_nm_labels.shape)\nMeta_Dataset[\"NEARMISS\"] = [train_nm_features.to_numpy(), train_nm_labels.to_numpy(), test_nm_features.to_numpy(), test_nm_labels.to_numpy()]\n\nprint(\"Splitting Random_Sampling : \")\ntrain_rs_features, \\\ntest_rs_features, \\\ntrain_rs_labels, \\\ntest_rs_labels=train_test_split(rs_features,rs_labels,test_size=0.2,random_state=1)\nprint(train_rs_features.shape, train_rs_labels.shape, test_rs_features.shape, test_rs_labels.shape)\nMeta_Dataset[\"Random Sampling\"] = [train_rs_features.to_numpy(), train_rs_labels.to_numpy(), test_rs_features.to_numpy(), test_rs_labels.to_numpy()]\n\nprint(\"Splitting MIX : \")\ntrain_mix_features, \\\ntest_mix_features, \\\ntrain_mix_labels, \\\ntest_mix_labels=train_test_split(mix_features,mix_labels,test_size=0.2,random_state=1)\nprint(train_mix_features.shape, train_mix_labels.shape, test_mix_features.shape, test_mix_labels.shape)\nMeta_Dataset[\"Mixing\"] = [train_mix_features.to_numpy(), train_mix_labels.to_numpy(), test_mix_features.to_numpy(), test_mix_labels.to_numpy()]\n","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:53:58.192968Z","iopub.execute_input":"2023-04-07T03:53:58.193315Z","iopub.status.idle":"2023-04-07T03:53:58.607304Z","shell.execute_reply.started":"2023-04-07T03:53:58.19328Z","shell.execute_reply":"2023-04-07T03:53:58.60639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check Meta_Dataset\nfor Name, values in Meta_Dataset.items():\n   print(Name) \n   print(values[0].shape, values[1].shape, values[2].shape, values[3].shape)","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:53:58.608651Z","iopub.execute_input":"2023-04-07T03:53:58.608966Z","iopub.status.idle":"2023-04-07T03:53:58.615147Z","shell.execute_reply.started":"2023-04-07T03:53:58.608935Z","shell.execute_reply":"2023-04-07T03:53:58.613905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"If you take all of the Dataset is will be too long to train and test. For testing purpose, NearMiss Undersampling data is used","metadata":{}},{"cell_type":"code","source":"# Selection NearMiss Datasets\ntrain_nm_features   = train_nm_features.to_numpy()\ntrain_nm_labels     = train_nm_labels.to_numpy() \ntest_nm_features    = test_nm_features.to_numpy()\ntest_nm_labels      = test_nm_labels.to_numpy()\nprint(train_nm_features.shape, train_nm_labels.shape, test_nm_features.shape, test_nm_labels.shape)","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:53:58.616735Z","iopub.execute_input":"2023-04-07T03:53:58.617905Z","iopub.status.idle":"2023-04-07T03:53:58.62894Z","shell.execute_reply.started":"2023-04-07T03:53:58.61786Z","shell.execute_reply":"2023-04-07T03:53:58.627613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Builing (25 model)","metadata":{}},{"cell_type":"code","source":"#Building Model Dict\nModels = {\n    \"Logistic Regression\": LogisticRegression(),                    #\n    \"Support Vector Classifier\": SVC(),                             # Ridge, SVC, LinearSVC, Passive_AC\n    \"Decision Tree\": DecisionTreeClassifier(max_depth=6),           #\n    \"KNearest\": KNeighborsClassifier(n_neighbors=5),                # doesn't have model.predict_proba so I left out.\n    \"GaussianNB\" : GaussianNB(),                                    #\n    \"LDA\" : LinearDiscriminantAnalysis(),                           # \n    \"Ridge\" : RidgeClassifier(),                                    #  \n    \"QDA\" : QuadraticDiscriminantAnalysis(),                        #\n    \"Bagging\" : BaggingClassifier(),                                #\n    \"MLP\" : MLPClassifier(),                                        #\n    \"LSVC\" : LinearSVC(),                                           #  \n    \"BernoulliNB\" : BernoulliNB(),                                  #  \n    \"Passive_AC\" : PassiveAggressiveClassifier(),                   # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #  \n    \"SGB\"     : GradientBoostingClassifier(n_estimators=100, random_state=9),\n    \"Adaboost\" : AdaBoostClassifier(n_estimators=100, random_state=9, algorithm='SAMME.R', learning_rate=0.8),\n    \"Extra_T\" : ExtraTreesClassifier(n_estimators=100, max_features=3),\n    \"R_forest\" : RandomForestClassifier(max_samples=0.9, n_estimators=100, max_features=3),\n    \"XGB\" : xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05)}","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:53:58.630124Z","iopub.execute_input":"2023-04-07T03:53:58.630711Z","iopub.status.idle":"2023-04-07T03:53:58.64195Z","shell.execute_reply.started":"2023-04-07T03:53:58.630684Z","shell.execute_reply":"2023-04-07T03:53:58.641286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import balanced_accuracy_score\nfrom sklearn.metrics import average_precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import matthews_corrcoef","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:53:58.642895Z","iopub.execute_input":"2023-04-07T03:53:58.643347Z","iopub.status.idle":"2023-04-07T03:53:58.652335Z","shell.execute_reply.started":"2023-04-07T03:53:58.643322Z","shell.execute_reply":"2023-04-07T03:53:58.651535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This function to calculate all of the evaluation matrix\n\ndef calculate_socre(classifier, test_features, test_labels):\n\n    predictions   = classifier.predict(test_features)\n    base_score   = classifier.score(test_sm_features,test_sm_labels)\n    accuracy     = accuracy_score(test_labels, predictions)\n    acc_bal      = balanced_accuracy_score(test_labels, predictions)\n    av_precision = average_precision_score(test_labels, predictions)\n    recall       = recall_score(test_labels, predictions)#Set df_used to the fraudulent transactions' dataset.\n    f1           = f1_score(test_labels, predictions)\n    roc          = roc_auc_score(test_labels, classifier.predict_proba(test_features)[:, 1])\n    mcc          = matthews_corrcoef(test_labels, predictions)\n    score = {\n        \"base_score\"     : round(base_score,3),\n        \"accuary\"        : round(accuracy,3),\n        \"acc_bal\"        : round(acc_bal,3),\n        \"av_precision\"   : round(av_precision,3),\n        \"recall\"         : round(recall,3),\n        \"f1\"             : round(f1,3),\n        \"roc\"            : round(roc,3),\n        \"mcc\"            : round(mcc,3)   }\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:53:58.653602Z","iopub.execute_input":"2023-04-07T03:53:58.65406Z","iopub.status.idle":"2023-04-07T03:53:58.667883Z","shell.execute_reply.started":"2023-04-07T03:53:58.654033Z","shell.execute_reply":"2023-04-07T03:53:58.666419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This function train all the Dataset and all models\ndef Train_all_Model():\n\n    Dataset_scores = {}\n\n    for Name, values in Meta_Dataset.items():\n        print(f\"The {Name} Dataset is using.........\")\n        i = 1\n        Model_scores = {} #Model = Socre\n        for Model_Name, classifier in Models.items():\n            print(f\"{i}. {Model_Name}\")\n            classifier.fit(values[0], values[1])\n            score = calculate_socre(classifier=classifier,\n                                    test_features=values[2],\n                                    test_labels=values[3])\n            i = i+1\n            print(f\"{score}\")\n            Model_scores[Model_Name] = score\n        print(\"________________________________________\")\n        Dataset_scores[Name] = Model_scores\n    return Dataset_scores","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:53:58.669198Z","iopub.execute_input":"2023-04-07T03:53:58.669669Z","iopub.status.idle":"2023-04-07T03:53:58.679322Z","shell.execute_reply.started":"2023-04-07T03:53:58.669636Z","shell.execute_reply":"2023-04-07T03:53:58.678277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This may take nearly 2 Hr to run all the models.","metadata":{}},{"cell_type":"code","source":"# Dataset_scores = Train_all_Model()","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:53:58.680668Z","iopub.execute_input":"2023-04-07T03:53:58.681267Z","iopub.status.idle":"2023-04-07T03:53:58.690987Z","shell.execute_reply.started":"2023-04-07T03:53:58.681231Z","shell.execute_reply":"2023-04-07T03:53:58.690126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For testing purpose, NearMiss undersampling dataset is used, and calculate_score function is modifed by removeing roc","metadata":{}},{"cell_type":"code","source":"def calculate_nm_score(classifier, test_features=test_nm_features, test_labels=test_nm_labels):\n\n    predictions   = classifier.predict(test_features)\n    base_score   = classifier.score(test_sm_features,test_sm_labels)\n    accuracy     = accuracy_score(test_labels, predictions)\n    acc_bal      = balanced_accuracy_score(test_labels, predictions)\n    av_precision = average_precision_score(test_labels, predictions)\n    recall       = recall_score(test_labels, predictions)#Set df_used to the fraudulent transactions' dataset.\n    f1           = f1_score(test_labels, predictions)\n    mcc          = matthews_corrcoef(test_labels, predictions)\n    score = {\n        \"base_score\"     : round(base_score,3),\n        \"accuary\"        : round(accuracy,3),\n        \"acc_bal\"        : round(acc_bal,3),\n        \"av_precision\"   : round(av_precision,3),\n        \"recall\"         : round(recall,3),\n        \"f1\"             : round(f1,3),\n        \"mcc\"            : round(mcc,3)   }\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:53:58.69257Z","iopub.execute_input":"2023-04-07T03:53:58.692887Z","iopub.status.idle":"2023-04-07T03:53:58.701561Z","shell.execute_reply.started":"2023-04-07T03:53:58.692854Z","shell.execute_reply":"2023-04-07T03:53:58.700476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for short in time,and resources, NearMiss undersampling data is taken\ndef train_nm_dataset():\n    i = 1\n    Model_scores = {} #Model = Socre\n    for Model_Name, classifier in Models.items():\n        print(f\"{i}. {Model_Name}\")\n        classifier.fit(train_nm_features, train_nm_labels)\n        score = calculate_nm_score(classifier=classifier)\n        i = i+1\n        print(f\"{score}\")\n        print(\"________________________________________\")\n        Model_scores[Model_Name] = score\n    return Model_scores","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:53:58.702567Z","iopub.execute_input":"2023-04-07T03:53:58.703467Z","iopub.status.idle":"2023-04-07T03:53:58.711677Z","shell.execute_reply.started":"2023-04-07T03:53:58.703414Z","shell.execute_reply":"2023-04-07T03:53:58.710422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This may take short because of NearMiss undersampling dataset, but data result are not good","metadata":{}},{"cell_type":"code","source":"nm_Model_score = train_nm_dataset()","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:53:58.7128Z","iopub.execute_input":"2023-04-07T03:53:58.713808Z","iopub.status.idle":"2023-04-07T03:54:10.149512Z","shell.execute_reply.started":"2023-04-07T03:53:58.71377Z","shell.execute_reply":"2023-04-07T03:54:10.148656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lgb\n\nparams = {\n          'boosting_type': 'gbdt',\n          'objective': 'binary',\n          'metric':'auc',\n          'learning_rate': 0.05,\n          'num_leaves': 7,  # we should let it be smaller than 2^(max_depth)\n          'max_depth': 4,  # -1 means no limit\n          'min_child_samples': 100,  # Minimum number of data need in a child(min_data_in_leaf)\n          'max_bin': 100,  # Number of bucketed bin for feature values\n          'subsample': 0.9,  # Subsample ratio of the training instance.\n          'subsample_freq': 1,  # frequence of subsample, <=0 means no enable\n          'colsample_bytree': 0.7,  # Subsample ratio of columns when constructing each tree.\n          'min_child_weight': 0,  # Minimum sum of instance weight(hessian) needed in a child(leaf)\n          'min_split_gain': 0,  # lambda_l1, lambda_l2 and min_gain_to_split to regularization\n          'nthread': 8,\n          'verbose': 0,\n          'scale_pos_weight':150, # because training data is extremely unbalanced \n         }\n\n\nlgb_train = lgb.Dataset(train_nm_features, train_nm_labels,  params={'verbose': -1})\nlgb_test = lgb.Dataset(train_nm_features, train_nm_labels,  params={'verbose': -1}, reference=lgb_train)\n\nLGBM = lgb.train(params, lgb_train, valid_sets=[lgb_train, lgb_test], verbose_eval=False)\nLGBM_pred=LGBM.predict(test_nm_features)\nLGBM_pred = LGBM_pred.round()\n","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:10.152437Z","iopub.execute_input":"2023-04-07T03:54:10.152803Z","iopub.status.idle":"2023-04-07T03:54:10.992815Z","shell.execute_reply.started":"2023-04-07T03:54:10.152772Z","shell.execute_reply":"2023-04-07T03:54:10.991757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LGBM_f1_score = f1_score(y_true=test_nm_labels,\n                      y_pred=LGBM_pred)\nLGBM_f1_score","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:10.994289Z","iopub.execute_input":"2023-04-07T03:54:10.994551Z","iopub.status.idle":"2023-04-07T03:54:11.002482Z","shell.execute_reply.started":"2023-04-07T03:54:10.994519Z","shell.execute_reply":"2023-04-07T03:54:11.001829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Catboost=CatBoostClassifier(eval_metric='Accuracy',use_best_model=True,random_seed=42,)\nCatboost.fit(train_nm_features,train_nm_labels,eval_set=(test_nm_features,test_nm_labels))","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:11.003393Z","iopub.execute_input":"2023-04-07T03:54:11.003766Z","iopub.status.idle":"2023-04-07T03:54:14.426609Z","shell.execute_reply.started":"2023-04-07T03:54:11.003742Z","shell.execute_reply":"2023-04-07T03:54:14.425844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_pred = Catboost.predict(test_nm_features)\ncat_F1_score = f1_score(y_true = test_nm_labels,\n                  y_pred = cat_pred)\ncat_F1_score","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:14.427794Z","iopub.execute_input":"2023-04-07T03:54:14.428307Z","iopub.status.idle":"2023-04-07T03:54:14.43914Z","shell.execute_reply.started":"2023-04-07T03:54:14.428276Z","shell.execute_reply":"2023-04-07T03:54:14.438132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Stacking + SMOTE \nBecause of Training Time, Datasets and Models are selected just to test the stacking\n* Base Models = Random Forest, K Nearest Neighbors\n* Stack Models = Logistic Regression\n* Dataset = Oversampling Dataset with SMOTE","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import StackingClassifier\n\nbase_models=[('RF',RandomForestClassifier(max_samples=0.9,n_jobs=-1)),('knn',KNeighborsClassifier(n_neighbors=5,n_jobs=-1))]\nmeta_model = LogisticRegression(n_jobs=-1)\nstacking_model = StackingClassifier(estimators=base_models, final_estimator=meta_model, passthrough=True, cv=3,n_jobs=-1)","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:14.440326Z","iopub.execute_input":"2023-04-07T03:54:14.44058Z","iopub.status.idle":"2023-04-07T03:54:14.44649Z","shell.execute_reply.started":"2023-04-07T03:54:14.440554Z","shell.execute_reply":"2023-04-07T03:54:14.445089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This take 20 min to run on my laptop","metadata":{}},{"cell_type":"code","source":"# stacking_model.fit(train_sm_features,train_sm_labels)\n# acc=stacking_model.score(test_sm_features,test_sm_labels)","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:14.448141Z","iopub.execute_input":"2023-04-07T03:54:14.448459Z","iopub.status.idle":"2023-04-07T03:54:14.45573Z","shell.execute_reply.started":"2023-04-07T03:54:14.448429Z","shell.execute_reply":"2023-04-07T03:54:14.454779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On oversampling(SMOTE) dataset, the stack model get 0(False Negative) which is very good. But on undersampling data. It seem little overfit.","metadata":{}},{"cell_type":"code","source":"stacking_model.fit(train_nm_features,train_nm_labels)\nacc=stacking_model.score(test_nm_features,test_nm_labels)","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:14.456968Z","iopub.execute_input":"2023-04-07T03:54:14.457277Z","iopub.status.idle":"2023-04-07T03:54:15.318514Z","shell.execute_reply.started":"2023-04-07T03:54:14.457245Z","shell.execute_reply":"2023-04-07T03:54:15.317506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ny_pred = stacking_model.predict(test_nm_features)\nconf_matrix = confusion_matrix(test_nm_labels, y_pred)\nsns.heatmap(conf_matrix, annot = True, fmt='g')","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:15.319596Z","iopub.execute_input":"2023-04-07T03:54:15.319842Z","iopub.status.idle":"2023-04-07T03:54:15.516915Z","shell.execute_reply.started":"2023-04-07T03:54:15.319814Z","shell.execute_reply":"2023-04-07T03:54:15.515793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(test_nm_labels, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:15.518315Z","iopub.execute_input":"2023-04-07T03:54:15.518552Z","iopub.status.idle":"2023-04-07T03:54:15.528856Z","shell.execute_reply.started":"2023-04-07T03:54:15.518528Z","shell.execute_reply":"2023-04-07T03:54:15.527559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stack_f1_score = f1_score(y_true=test_nm_labels,\n                          y_pred=y_pred)\nstack_f1_score","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:15.530475Z","iopub.execute_input":"2023-04-07T03:54:15.530779Z","iopub.status.idle":"2023-04-07T03:54:15.539959Z","shell.execute_reply.started":"2023-04-07T03:54:15.530749Z","shell.execute_reply":"2023-04-07T03:54:15.538496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tensorflow","metadata":{}},{"cell_type":"markdown","source":"#### Base Model","metadata":{}},{"cell_type":"code","source":"n_inputs = sm_features.shape[1]\nx_inputs = nm_features.shape[1]\nprint(n_inputs, x_inputs)\n\ntf.set_seed = 42\n\nbase_model = Sequential([\n    Dense(n_inputs, input_shape=(n_inputs,), activation='relu'),\n    Dense(32, activation='relu'),\n    Dense(1, activation='sigmoid')\n])\n\nbase_model.summary()\n\nbase_model.compile(\n    optimizer = Adam(learning_rate= 0.0001),\n    loss= 'binary_crossentropy',\n    metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:15.541381Z","iopub.execute_input":"2023-04-07T03:54:15.54166Z","iopub.status.idle":"2023-04-07T03:54:15.742248Z","shell.execute_reply.started":"2023-04-07T03:54:15.541632Z","shell.execute_reply":"2023-04-07T03:54:15.741138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import itertools\n\n# Create a confusion matrix\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title, fontsize=14)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:15.743626Z","iopub.execute_input":"2023-04-07T03:54:15.743937Z","iopub.status.idle":"2023-04-07T03:54:15.753515Z","shell.execute_reply.started":"2023-04-07T03:54:15.743906Z","shell.execute_reply":"2023-04-07T03:54:15.752481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"undersample_model = base_model\nundersample_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:15.754652Z","iopub.execute_input":"2023-04-07T03:54:15.755011Z","iopub.status.idle":"2023-04-07T03:54:15.783695Z","shell.execute_reply.started":"2023-04-07T03:54:15.754974Z","shell.execute_reply":"2023-04-07T03:54:15.782333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.set_seed = 42\nundersample_history = undersample_model.fit(train_nm_features,\n                        train_nm_labels,\n                        batch_size= 25,\n                        epochs=20,\n                        validation_data=(test_nm_features,test_nm_labels))","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:15.785416Z","iopub.execute_input":"2023-04-07T03:54:15.785774Z","iopub.status.idle":"2023-04-07T03:54:19.382513Z","shell.execute_reply.started":"2023-04-07T03:54:15.785736Z","shell.execute_reply":"2023-04-07T03:54:19.38162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"undersample_predictions = undersample_model.predict(test_nm_features, batch_size=200, verbose=0)\nundersample_predictions.shape","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:19.383951Z","iopub.execute_input":"2023-04-07T03:54:19.384273Z","iopub.status.idle":"2023-04-07T03:54:19.500741Z","shell.execute_reply.started":"2023-04-07T03:54:19.384243Z","shell.execute_reply":"2023-04-07T03:54:19.499517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"By comparing f1_score :  undersampling_ANN to stack, ","metadata":{}},{"cell_type":"code","source":"undersample_fraud_predictions=np.round(undersample_predictions)\nundersample_f1 = f1_score(y_true=test_nm_labels,\n                          y_pred=undersample_fraud_predictions)\nundersample_f1","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:19.502064Z","iopub.execute_input":"2023-04-07T03:54:19.50233Z","iopub.status.idle":"2023-04-07T03:54:19.510728Z","shell.execute_reply.started":"2023-04-07T03:54:19.502305Z","shell.execute_reply":"2023-04-07T03:54:19.509665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nundersample_cm = confusion_matrix(test_nm_labels, undersample_fraud_predictions)\nactual_cm = confusion_matrix(test_nm_labels, test_nm_labels)\nlabels = ['No Fraud', 'Fraud']\n\nfig = plt.figure(figsize=(16,8))\n\nfig.add_subplot(221)\nplot_confusion_matrix(undersample_cm, labels, title=\"Random UnderSample \\n Confusion Matrix\", cmap=plt.cm.Reds)\n\nfig.add_subplot(222)\nplot_confusion_matrix(actual_cm, labels, title=\"Confusion Matrix \\n (with 100% accuracy)\", cmap=plt.cm.Greens)","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:19.512003Z","iopub.execute_input":"2023-04-07T03:54:19.51229Z","iopub.status.idle":"2023-04-07T03:54:19.881025Z","shell.execute_reply.started":"2023-04-07T03:54:19.512265Z","shell.execute_reply":"2023-04-07T03:54:19.878728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oversample_model = base_model\noversample_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:19.882764Z","iopub.execute_input":"2023-04-07T03:54:19.883096Z","iopub.status.idle":"2023-04-07T03:54:19.89892Z","shell.execute_reply.started":"2023-04-07T03:54:19.88304Z","shell.execute_reply":"2023-04-07T03:54:19.898271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This model takes 30 min on my laptop","metadata":{}},{"cell_type":"code","source":"# oversample_history = oversample_model.fit(train_sm_features,\n#                         train_sm_labels,\n#                         batch_size= 25,\n#                         epochs=20,\n#                         validation_data=(test_sm_features,test_sm_labels))","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:19.899851Z","iopub.execute_input":"2023-04-07T03:54:19.900109Z","iopub.status.idle":"2023-04-07T03:54:19.905237Z","shell.execute_reply.started":"2023-04-07T03:54:19.900057Z","shell.execute_reply":"2023-04-07T03:54:19.904009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# oversample_predictions = oversample_model.predict(test_sm_features, batch_size=200, verbose=0)\n# oversample_predictions.shape","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:19.906456Z","iopub.execute_input":"2023-04-07T03:54:19.906768Z","iopub.status.idle":"2023-04-07T03:54:19.914003Z","shell.execute_reply.started":"2023-04-07T03:54:19.90674Z","shell.execute_reply":"2023-04-07T03:54:19.913025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# oversample_fraud_predictions=np.round(oversample_predictions)\n# f1_oversample = f1_score(y_true=test_sm_labels,\n#                          y_pred=oversample_fraud_predictions)\n# f1_oversample","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:19.91527Z","iopub.execute_input":"2023-04-07T03:54:19.91552Z","iopub.status.idle":"2023-04-07T03:54:19.922636Z","shell.execute_reply.started":"2023-04-07T03:54:19.915495Z","shell.execute_reply":"2023-04-07T03:54:19.921671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# oversample_smote = confusion_matrix(test_sm_labels, oversample_fraud_predictions)\n# actual_cm = confusion_matrix(test_sm_labels, test_sm_labels)\n# labels = ['No Fraud', 'Fraud']\n\n# fig = plt.figure(figsize=(16,8))\n\n# fig.add_subplot(221)\n# plot_confusion_matrix(oversample_smote, labels, title=\"OverSample (SMOTE) \\n Confusion Matrix\", cmap=plt.cm.Oranges)\n\n# fig.add_subplot(222)\n# plot_confusion_matrix(actual_cm, labels, title=\"Confusion Matrix \\n (with 100% accuracy)\", cmap=plt.cm.Greens)","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:19.92384Z","iopub.execute_input":"2023-04-07T03:54:19.924066Z","iopub.status.idle":"2023-04-07T03:54:19.933062Z","shell.execute_reply.started":"2023-04-07T03:54:19.924043Z","shell.execute_reply":"2023-04-07T03:54:19.932121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From this far, we have seem stacking models and oversampling(SMOTE) DNN model are so great.","metadata":{}},{"cell_type":"markdown","source":"#### CNN model","metadata":{}},{"cell_type":"code","source":"train_sm_features = np.array(train_sm_features)\ntest_sm_features = np.array(test_sm_features)","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:19.93443Z","iopub.execute_input":"2023-04-07T03:54:19.934776Z","iopub.status.idle":"2023-04-07T03:54:19.958415Z","shell.execute_reply.started":"2023-04-07T03:54:19.934741Z","shell.execute_reply":"2023-04-07T03:54:19.957345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reshaping the input to 3D.\ntrain_sm_features_cnn = train_sm_features.reshape(train_sm_features.shape[0],train_sm_features.shape[1],1)\ntest_sm_features_cnn = test_sm_features.reshape(test_sm_features.shape[0],test_sm_features.shape[1],1)","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:19.959765Z","iopub.execute_input":"2023-04-07T03:54:19.960119Z","iopub.status.idle":"2023-04-07T03:54:19.965214Z","shell.execute_reply.started":"2023-04-07T03:54:19.960068Z","shell.execute_reply":"2023-04-07T03:54:19.964327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers\n\n\n# Build the model\ncnn_model = keras.Sequential([\n        # keras.Input(shape=input_shape),\n        layers.Conv1D(32, 2, activation=\"relu\",input_shape=train_sm_features_cnn[0].shape),\n        layers.Dropout(0.5),\n        layers.Conv1D(64, 2, activation=\"relu\"),\n        layers.Dropout(0.5),\n        layers.Conv1D(64, 2, activation=\"relu\"),\n        layers.Dropout(0.5),\n        layers.Flatten(),\n        layers.Dropout(0.5),\n        layers.Dense(1, activation=\"sigmoid\"),\n    ])\ncnn_model.summary()\n\ncnn_model.compile(\n    optimizer = Adam(learning_rate= 0.0001),\n    loss= 'binary_crossentropy',\n    metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:19.966332Z","iopub.execute_input":"2023-04-07T03:54:19.966622Z","iopub.status.idle":"2023-04-07T03:54:20.071673Z","shell.execute_reply.started":"2023-04-07T03:54:19.96659Z","shell.execute_reply":"2023-04-07T03:54:20.070691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Running this model almosts take 1Hr on my laptop, if you like to run, just run on gpu","metadata":{}},{"cell_type":"code","source":"# cnn_history = cnn_model.fit(train_sm_features_cnn,\n#                         train_sm_labels,\n#                         batch_size= 25,\n#                         epochs=20,\n#                         validation_data=(test_sm_features_cnn,test_sm_labels))","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:20.07301Z","iopub.execute_input":"2023-04-07T03:54:20.073312Z","iopub.status.idle":"2023-04-07T03:54:20.080248Z","shell.execute_reply.started":"2023-04-07T03:54:20.073284Z","shell.execute_reply":"2023-04-07T03:54:20.07884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plotLearningCurve(history,epochs=20):\n  epochRange = range(1,epochs+1)\n  plt.plot(epochRange,history.history['accuracy'])\n  plt.plot(epochRange,history.history['val_accuracy'])\n  plt.title('Model Accuracy')\n  plt.xlabel('Epoch')\n  plt.ylabel('Accuracy')\n  plt.legend(['Train','Validation'],loc='upper left')\n  plt.show()\n\n  plt.plot(epochRange,history.history['loss'])\n  plt.plot(epochRange,history.history['val_loss'])\n  plt.title('Model Loss')\n  plt.xlabel('Epoch')\n  plt.ylabel('Loss')\n  plt.legend(['Train','Validation'],loc='upper left')\n  plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:20.081636Z","iopub.execute_input":"2023-04-07T03:54:20.081999Z","iopub.status.idle":"2023-04-07T03:54:20.092858Z","shell.execute_reply.started":"2023-04-07T03:54:20.081967Z","shell.execute_reply":"2023-04-07T03:54:20.091733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plotLearningCurve(undersample_history)","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:20.094044Z","iopub.execute_input":"2023-04-07T03:54:20.094312Z","iopub.status.idle":"2023-04-07T03:54:20.47316Z","shell.execute_reply.started":"2023-04-07T03:54:20.094288Z","shell.execute_reply":"2023-04-07T03:54:20.472175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plotLearningCurve(oversample_history)","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:20.474139Z","iopub.execute_input":"2023-04-07T03:54:20.474401Z","iopub.status.idle":"2023-04-07T03:54:20.478229Z","shell.execute_reply.started":"2023-04-07T03:54:20.474375Z","shell.execute_reply":"2023-04-07T03:54:20.477307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plotLearningCurve(cnn_history)","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:20.479366Z","iopub.execute_input":"2023-04-07T03:54:20.479712Z","iopub.status.idle":"2023-04-07T03:54:20.489064Z","shell.execute_reply.started":"2023-04-07T03:54:20.479677Z","shell.execute_reply":"2023-04-07T03:54:20.487782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Hyper-parameter Tuing","metadata":{}},{"cell_type":"markdown","source":"GridSearchCV and RandomizeSearchCV  \n\nIn general, GridSearchCV is best suited for smaller hyperparameter spaces, where it is feasible to test all possible combinations. RandomizedSearchCV is best suited for larger hyperparameter spaces, where it is not feasible to test all possible combinations, and random sampling can efficiently search a wide range of hyperparameters.\n\nIt's important to note that both GridSearchCV and RandomizedSearchCV can be combined with other techniques, such as cross-validation and feature selection, to further improve the performance of machine learning models. The choice of hyperparameter tuning technique ultimately depends on the size and complexity of the hyperparameter space, as well as the available computational resources.","metadata":{}},{"cell_type":"markdown","source":"#### Test for hyperparameter tuning","metadata":{}},{"cell_type":"code","source":"#Convert to arrays to feed to the classifications algorithms\nclassifiers = {\n    \"Logistic Regression\": LogisticRegression(),\n    \"Support Vector Classifier\": SVC(),\n    \"Decision Tree\": DecisionTreeClassifier(),\n    \"KNearest\": KNeighborsClassifier()\n}","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:20.490473Z","iopub.execute_input":"2023-04-07T03:54:20.490846Z","iopub.status.idle":"2023-04-07T03:54:20.498848Z","shell.execute_reply.started":"2023-04-07T03:54:20.49081Z","shell.execute_reply":"2023-04-07T03:54:20.49797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"cross_validation also take alot of time (more than 30 min ) therefore I change from SMOTE dataset to NEARMISS dataset","metadata":{}},{"cell_type":"code","source":"#Calculate the cross-validation score for each classifier\nprint('Cross-Validation Scores:-')\nfor key, classifier in classifiers.items():\n    classifier.fit(train_nm_features, train_nm_labels)\n    cv_score = cross_val_score(classifier, train_nm_features, train_nm_labels, cv=3)\n    print('{}: {}'.format(key,round(cv_score.mean()*100.0, 2)))","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:20.499917Z","iopub.execute_input":"2023-04-07T03:54:20.500323Z","iopub.status.idle":"2023-04-07T03:54:20.700726Z","shell.execute_reply.started":"2023-04-07T03:54:20.500278Z","shell.execute_reply":"2023-04-07T03:54:20.699574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {\n    \"Logistic Regression\": {\"penalty\": [ 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]},\n    \"Support Vector Classifier\": {'C': [0.5, 0.7, 0.9, 1], 'kernel': ['rbf', 'poly', 'sigmoid', 'linear']},\n    \"Decision Tree\": {\"criterion\": [\"gini\", \"entropy\"], \"max_depth\": list(range(2,4,1)), \n              \"min_samples_leaf\": list(range(5,7,1))},\n    \"KNearest\": {\"n_neighbors\": list(range(2,5,1)), 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']}\n}","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:20.701972Z","iopub.execute_input":"2023-04-07T03:54:20.703122Z","iopub.status.idle":"2023-04-07T03:54:20.710022Z","shell.execute_reply.started":"2023-04-07T03:54:20.703051Z","shell.execute_reply":"2023-04-07T03:54:20.709201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"GridsearchCV","metadata":{}},{"cell_type":"code","source":"#Using Grid search for finding the most optimal hyperparameters\ndef gridsearch(classifier, params):\n    grid_classifier = GridSearchCV(classifier, params)\n    grid_classifier.fit(train_nm_features, train_nm_labels)\n    best_classifier = grid_classifier.best_estimator_\n    return best_classifier","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:20.711224Z","iopub.execute_input":"2023-04-07T03:54:20.712351Z","iopub.status.idle":"2023-04-07T03:54:20.720918Z","shell.execute_reply.started":"2023-04-07T03:54:20.712311Z","shell.execute_reply":"2023-04-07T03:54:20.719949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Scores after applying Grid Search\nprint('Cross-Validation Scores after applying GridSearch:-')\nfor key, classifier in classifiers.items():\n    best_classifier = gridsearch(classifier,params[key])\n    cv_score = cross_val_score(best_classifier, train_nm_features, train_nm_labels, cv=3)\n    print('{}: {}'.format(key,round(cv_score.mean()*100.0, 2)))","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:20.722107Z","iopub.execute_input":"2023-04-07T03:54:20.722475Z","iopub.status.idle":"2023-04-07T03:54:22.895465Z","shell.execute_reply.started":"2023-04-07T03:54:20.722438Z","shell.execute_reply":"2023-04-07T03:54:22.89446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"RandomizedSearchCV","metadata":{}},{"cell_type":"code","source":"# from sklearn.model_selection import RandomizedSearchCV\n# from sklearn.ensemble import RandomForestClassifier\n\n# # Create an instance of RandomizedSearchCV\n# random_search = RandomizedSearchCV(models,  n_iter=20, cv=5)\n\n# # Fit RandomizedSearchCV to the dataset\n# random_search.fit(data, target)\n\n# # Print the best hyperparameters and the corresponding mean cross-validation score\n# print(\"Best hyperparameters: \", random_search.best_params_)\n# print(\"Best score: \", random_search.best_score_)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:22.896578Z","iopub.execute_input":"2023-04-07T03:54:22.897026Z","iopub.status.idle":"2023-04-07T03:54:22.901725Z","shell.execute_reply.started":"2023-04-07T03:54:22.896991Z","shell.execute_reply":"2023-04-07T03:54:22.900802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <a id='learn' > Learning Curve</a>\nA learning curve refers to a plot of the prediction accuracy/error vs. the training set size (i.e: how better does the model get at predicting the target as you the increase number of instances used to train it). Usually both the training and test/validation performance are plotted together so we can diagnose the **bias-variance tradeoff** (i.e determine if we benefit from adding more training data, and assess the model complexity by controlling regularization or number of features).\n<img src='https://histalk2.com/wp-content/uploads/2018/12/image-30.png' height=400 width=200/>","metadata":{}},{"cell_type":"markdown","source":"Just use logistic regression and NearMiss Datasets","metadata":{}},{"cell_type":"code","source":"# Let's Plot LogisticRegression Learning Curve\nfrom sklearn.model_selection import ShuffleSplit\nfrom sklearn.model_selection import learning_curve\n\ndef plot_learning_curve(estimator1, X, y, ylim=None, cv=None,\n                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n    f, ((ax1)) = plt.subplots(1, figsize=(20,14), sharey=True)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    # First Estimator\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator1, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    ax1.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"#ff9124\")\n    ax1.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"#2492ff\")\n    ax1.plot(train_sizes, train_scores_mean, 'o-', color=\"#ff9124\",\n             label=\"Training score\")\n    ax1.plot(train_sizes, test_scores_mean, 'o-', color=\"#2492ff\",\n             label=\"Cross-validation score\")\n    ax1.set_title(\"Logistic Regression Learning Curve\", fontsize=14)\n    ax1.set_xlabel('Training size (m)')\n    ax1.set_ylabel('Score')\n    ax1.grid(True)\n    ax1.legend(loc=\"best\")\n    return plt","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:22.902744Z","iopub.execute_input":"2023-04-07T03:54:22.903567Z","iopub.status.idle":"2023-04-07T03:54:22.914884Z","shell.execute_reply.started":"2023-04-07T03:54:22.903532Z","shell.execute_reply":"2023-04-07T03:54:22.914128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=42)\n# plot_learning_curve(log_reg, knears_neighbors, svc, tree_clf, X_train, y_train, (0.87, 1.01), cv=cv, n_jobs=4)","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:22.916003Z","iopub.execute_input":"2023-04-07T03:54:22.916925Z","iopub.status.idle":"2023-04-07T03:54:22.926266Z","shell.execute_reply.started":"2023-04-07T03:54:22.916892Z","shell.execute_reply":"2023-04-07T03:54:22.92535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"log_reg = LogisticRegression()\nlog_reg.fit(train_nm_features,train_nm_labels)","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:22.92727Z","iopub.execute_input":"2023-04-07T03:54:22.9276Z","iopub.status.idle":"2023-04-07T03:54:22.962532Z","shell.execute_reply.started":"2023-04-07T03:54:22.927565Z","shell.execute_reply":"2023-04-07T03:54:22.961606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=42)\nplot_learning_curve(log_reg, train_nm_features, train_nm_labels, (0.87, 1.01), cv=cv, n_jobs=4)","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:22.96597Z","iopub.execute_input":"2023-04-07T03:54:22.966544Z","iopub.status.idle":"2023-04-07T03:54:33.240343Z","shell.execute_reply.started":"2023-04-07T03:54:22.96651Z","shell.execute_reply":"2023-04-07T03:54:33.23917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <a id='roc'>AUC-ROC Curve</a>\nAUC - ROC curve is a performance measurement for classification problem at various thresholds settings. ROC is a probability curve and AUC represents degree or measure of separability. It tells how much model is capable of distinguishing between classes. Higher the AUC, better the model is at predicting 0s as 0s and 1s as 1s. By analogy, Higher the AUC, better the model is at distinguishing between patients with disease and no disease.\n\nThe ROC curve is plotted with TPR against the FPR where TPR is on y-axis and FPR is on the x-axis.\n<img src='https://miro.medium.com/max/722/1*pk05QGzoWhCgRiiFbz-oKQ.png'/>","metadata":{}},{"cell_type":"code","source":"#Predicting proba\ny_pred_prob = log_reg.predict_proba(train_nm_features)[:, 1]\n# roc_auc_score(test_nm_labels, log_reg.predict_proba(test_nm_features)[:, 1])\n\n# Generate precision recall curve values: precision, recall, thresholds\nprecision, recall, thresholds = precision_recall_curve(train_nm_labels, y_pred_prob)\n\n# Plot ROC curve\nplt.plot(precision, recall)\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision Recall Curve')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:33.24206Z","iopub.execute_input":"2023-04-07T03:54:33.24245Z","iopub.status.idle":"2023-04-07T03:54:33.566295Z","shell.execute_reply.started":"2023-04-07T03:54:33.24241Z","shell.execute_reply":"2023-04-07T03:54:33.565214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<!-- #ROC Curve\n'''log_pred = cross_val_predict(log_reg, X_train, y_train, cv=5)\nsvc_pred = cross_val_predict(svc, X_train, y_train, cv=5)\ntree_pred = cross_val_predict(decision_tree, X_train, y_train, cv=5)\nknear_pred = cross_val_predict(knearest, X_train, y_train, cv=5)'''\n\nlog_pred = log_reg.predict(X_test)\nsvc_pred = svc.predict(X_test)\ntree_pred = decision_tree.predict(X_test)\nknear_pred = knearest.predict(X_test)\n\nlog_fpr, log_tpr, log_threshold = roc_curve(y_test, log_pred)\nsvc_fpr, svc_tpr, svc_threshold = roc_curve(y_test, svc_pred)\ntree_fpr, tree_tpr, tree_threshold = roc_curve(y_test, tree_pred)\nknear_fpr, knear_tpr, knear_threshold = roc_curve(y_test, knear_pred)\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(name='Logistic Regression Classifier Score: {:.4f}'.format(roc_auc_score(y_test, log_pred)),\n                         x=log_fpr,y=log_tpr,mode='lines'))\nfig.add_trace(go.Scatter(name='Support Vector Classifier Score: {:.4f}'.format(roc_auc_score(y_test, svc_pred)),\n                         x=svc_fpr,y=svc_tpr,mode='lines'))\nfig.add_trace(go.Scatter(name='Decision Tree Classifier Score: {:.4f}'.format(roc_auc_score(y_test, tree_pred)),\n                         x=tree_fpr,y=tree_tpr,mode='lines'))\nfig.add_trace(go.Scatter(name='K-Nearest Neighbors Classifier Score: {:.4f}'.format(roc_auc_score(y_test, knear_pred)),\n                         x=knear_fpr,y=knear_tpr,mode='lines'))\nfig.add_trace(go.Scatter(name='AUC-ROC=0.5',x=[0,1],y=[0,1],line=dict(dash='dot'),showlegend=False))\nfig.update_layout(\n    width=700,xaxis=dict(mirror=True,linewidth=2,linecolor='black'),\n    yaxis=dict(mirror=True,linewidth=2,linecolor='black'),\n    title='ROC Curve<br>(All Classifiers)',\n    template='seaborn',\n    legend=dict(\n        x=0.46,\n        y=0,\n        traceorder=\"normal\",\n        font=dict(\n            family=\"sans-serif\",\n            size=12,\n            color=\"black\"\n        ),\n        bgcolor=\"Lightgray\",\n        bordercolor=\"Black\",\n        borderwidth=2\n    ),\n     annotations=[\n        dict(\n            x=0.5,\n            y=0.5,\n            xref=\"x\",\n            yref=\"y\",\n            text=\"Minimum ROC Score of 50% <br> (This is the minimum score to get)\",\n            showarrow=True,\n            arrowhead=7,\n            ax=40,\n            ay=50\n        )\n    ]\n)\nfig.show() -->","metadata":{}},{"cell_type":"markdown","source":"### Final Socre on NearMiss Undersampling","metadata":{}},{"cell_type":"code","source":"nm_score_df = pd.DataFrame(nm_Model_score)\nnm_score_df = nm_score_df.transpose()\nnm_score_df","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:33.567569Z","iopub.execute_input":"2023-04-07T03:54:33.567914Z","iopub.status.idle":"2023-04-07T03:54:33.590257Z","shell.execute_reply.started":"2023-04-07T03:54:33.567879Z","shell.execute_reply":"2023-04-07T03:54:33.588677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nm_f1_score_df = nm_score_df.f1\nnm_f1_score_df","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:33.591772Z","iopub.execute_input":"2023-04-07T03:54:33.592144Z","iopub.status.idle":"2023-04-07T03:54:33.602274Z","shell.execute_reply.started":"2023-04-07T03:54:33.592064Z","shell.execute_reply":"2023-04-07T03:54:33.601286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_df = {\"LGBM_f1_score\" : LGBM_f1_score, \n          \"cat_F1_score\" : cat_F1_score,\n          \"stack_f1_score\" : stack_f1_score,\n          \"undersample_f1\" : undersample_f1\n}\nnew_df = pd.Series(new_df)\nnew_df","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:33.603434Z","iopub.execute_input":"2023-04-07T03:54:33.603745Z","iopub.status.idle":"2023-04-07T03:54:33.616253Z","shell.execute_reply.started":"2023-04-07T03:54:33.603717Z","shell.execute_reply":"2023-04-07T03:54:33.61532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nm_f1_score_df = nm_f1_score_df.append(new_df)","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:33.61738Z","iopub.execute_input":"2023-04-07T03:54:33.617637Z","iopub.status.idle":"2023-04-07T03:54:33.624116Z","shell.execute_reply.started":"2023-04-07T03:54:33.617612Z","shell.execute_reply":"2023-04-07T03:54:33.62323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nm_f1_score_df.columns = [\"Models\", \"f1_score\"]\nnm_f1_score_df = pd.DataFrame(nm_f1_score_df, columns=[ \"f1_score\"])\nnm_f1_score_df","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:33.626184Z","iopub.execute_input":"2023-04-07T03:54:33.626679Z","iopub.status.idle":"2023-04-07T03:54:33.643283Z","shell.execute_reply.started":"2023-04-07T03:54:33.626621Z","shell.execute_reply":"2023-04-07T03:54:33.642192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sns.lineplot(x=\"Models\",y=\"f1_socre\", data=nm_f1_score_df)","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:33.645133Z","iopub.execute_input":"2023-04-07T03:54:33.645467Z","iopub.status.idle":"2023-04-07T03:54:33.650846Z","shell.execute_reply.started":"2023-04-07T03:54:33.645432Z","shell.execute_reply":"2023-04-07T03:54:33.650248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Good result output on oversampling with SMOTE dataset\nThey are just copy from above cells. ","metadata":{}},{"cell_type":"code","source":"sm_stack = stacking_model","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:33.651605Z","iopub.execute_input":"2023-04-07T03:54:33.652206Z","iopub.status.idle":"2023-04-07T03:54:33.661997Z","shell.execute_reply.started":"2023-04-07T03:54:33.65218Z","shell.execute_reply":"2023-04-07T03:54:33.661135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sm_stack.fit(train_sm_features,train_sm_labels)\nacc=sm_stack.score(test_sm_features,test_sm_labels)","metadata":{"execution":{"iopub.status.busy":"2023-04-07T03:54:33.663058Z","iopub.execute_input":"2023-04-07T03:54:33.663384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ny_pred_sm = sm_stack.predict(test_sm_features)\nconf_matrix = confusion_matrix(test_sm_labels, y_pred_sm)\nsns.heatmap(conf_matrix, annot = True, fmt='g')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(test_sm_labels, y_pred_sm))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stack_f1_score = f1_score(y_true=test_sm_labels,\n                          y_pred=y_pred_sm)\nstack_f1_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.set_seed = 125\noversample_history = oversample_model.fit(train_sm_features,\n                        train_sm_labels,\n                        batch_size = 25,\n                        epochs = 20, # 20\n                        validation_data = (test_sm_features,test_sm_labels))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oversample_predictions = oversample_model.predict(test_sm_features, batch_size=200, verbose=0)\noversample_predictions.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oversample_fraud_predictions=np.round(oversample_predictions)\nf1_oversample = f1_score(y_true=test_sm_labels,\n                         y_pred=oversample_fraud_predictions)\nf1_oversample","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oversample_smote = confusion_matrix(test_sm_labels, oversample_fraud_predictions)\nactual_cm = confusion_matrix(test_sm_labels, test_sm_labels)\nlabels = ['No Fraud', 'Fraud']\n\nfig = plt.figure(figsize=(16,8))\n\nfig.add_subplot(221)\nplot_confusion_matrix(oversample_smote, labels, title=\"OverSample (SMOTE) \\n Confusion Matrix\", cmap=plt.cm.Oranges)\n\nfig.add_subplot(222)\nplot_confusion_matrix(actual_cm, labels, title=\"Confusion Matrix \\n (with 100% accuracy)\", cmap=plt.cm.Greens)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plotLearningCurve(oversample_history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}